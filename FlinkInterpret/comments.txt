
Комментарии к проекту FlinkInterpret

Цель проекта: понять как могут интерпретироваться конструкции Flink и какие характеристики могут быть достигнуты.

Если сильно упростить то, что я понял относительно Флинка, обработка распадается на отдельные (не связанные между собой)
процессы и этапы преобразований. Процесс - это не заканчивающийся этап. Этап преобразований (как и процесс) состоит из источника, 
вырабатывающего поток значений, преобразований этого потока и стока, куда поток "утекает". 

Мне показалось важным понять каким образом можно реализовать основную структуру данных DataStream. Я прпедположил, что DataStream 
это всего лишь способ обработки и подобрал некоторый вариант исходя из "старых структур", т.е. до появления Linq, IEnumerable и т.д.
Я попробовал известный вариант IEnumerator, т.е. перечислитель последовательности (потока) данных.

Источник MySource определяется как расширение IEnumerator в котором задается конструктор и формирователь элементов потока. Вот такой шаблон:
    class MySource : IEnumerator
    {
        object Current => throw new NotImplementedException();
        bool MoveNext() { throw new NotImplementedException(); }
        void Reset() { throw new NotImplementedException(); }
        object IEnumerator.Current => throw new NotImplementedException();
    }

В качестве примера зададим источник предложений, состоящих из слов. Слова сгенерируем конструктором, а в предложение будем включать по 50 случайно 
выбранных слов. Получается словарь из более, чем 1000 слов разного размера.  

Испытаем на скорость работы. На наборе из 200 тыс. строк по 50 слов время сканирования составляет 450 мс. т.е. около 2 млн. слов в секунду. 

Идея интерпретации некоторого Flink-выражения заключается в том, что сначала источник порождает цикл вида:

    while (source.MoveNext())
    {
        object element = source.Current;
        //... преобразование element -> e1 -> e2 ... с последующим        sink.Push(e);
    }

Варианты преобразований:

if (!predicate(e)) continue; // Filter фильтрация
... // продолжение

object e2 = Func(e1); // Map функциональное преобразование

object[] vec = VFunc(e1); // FlatMap
foreach (object e2 in vec)
{
    // преобразование e2
}

object key = keyFunc(e1); // KeyBy DataStream → KeyedStream
... // преобразование пары ключ-значение

// Reduce KeyedStream → DataStream
// Dictionary<object, object> hash = new Dictionary<object, object>(); // это должно быть снаружи цикла
object r_value = RVal(e1);
if (!hash.ContainsKey(key))
{
    hash.Add(key, r_value);
}
else
{
    hash[key] = reduce(hash[key], r_value);
}
// далее надо завершить циклы и выдать поток величин r_value

В принципе, можно написать интерпретатор Flink-выражений. Для этого достаточно в рамках конструирования и преобразования 
DataStream → KeyedStream → DataStream, можно соорудить древовидную структуру, которую потом проинтерпретировать. Но я попробую
вручную оттранслировать. Возьму код со страницы https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/datastream_api.html#example-program

    DataStream<Tuple2<String, Integer>> dataStream = env
            .socketTextStream("localhost", 9999)
            .flatMap(new Splitter())
            .keyBy(value -> value.f0)
            .window(TumblingProcessingTimeWindows.of(Time.seconds(5)))
            .sum(1);

Что я изменю? Вместо сетевого текстового источника, поставлю спроектированный генератор. Все буду делать в объектном базисе. window не понимаю и 
не реализовываю. Как понимать sum(1) - не знаю, буду предполагать, что это сумма по первому (?) полю, т.е. сумма единичек. 

Сделал цикл источника с получением предложения, сделал сплит и цикл по словам. Получилось 10 млн. слов, двойной цикл длится 800 мс. 
Теперь за циклом помещаю инициирование хеш-словаря и буду его наполнять парами { key, 1 }.

